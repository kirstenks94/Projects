{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Reddit Trading Strategy\n\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00001-4c43432a-e702-48ef-b3b7-b7661773f65b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Deliverables\n\n* `documentation.ipynb` .... This notebook contains information about the delivered files and how to use and maintain them.\n\n* `reddit_stock_analysis.ipynb` .... This notebook provides an in-depth evaluation of the `r/wallstreetbets` subreddit including a detailed sentiment analysis \n\n* `reddit_data_fetch.ipynb` ... This notebook provides code that automatically downloads reddit data (i.e., posts) and stores it such that it can be used as input data for any further processing.\n\n* `data_wsb/` ... This folder contains a collection of all reddit posts from the `r/wallstreetbets` subreddit between December 1st, 2020 and May 1st, 2021.\n\n\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00001-d9806fc6-af80-4d5b-a803-b196a9770abb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Input Data\n\n* `data_wsb/`\n\n  This folder contains the reddit posts used as input for the processing.\n  The data is stored as human-readable CSV files with the following columns:\n\n    * `timestamp` (type: Datetime) ... The point in time that the post was submitted.\n    * `id` (type: String) ... The unique ID of the post.\n    * `title` (type: String) ... The title of the post.\n    * `body` (type: String, optional) ... The text of the post.\n    * `num_comments` (type: Integer) ... The number of comments that the post has got at the time the dataset was assembled.\n    * `score` (type: Integer) ... The reddit score (upvotes/downvotes) that the post has got at the time the dataset was assembled.\n\n  Example:\n    \n  > timestamp,id,title,body,num_comments,score  \n  > 2021-01-28 00:43:01,l6jb22,WE'RE BACK! LETS BOOM BOYS! ðŸš€ ðŸš€,\"We need to stay strong. Do not let this destory us, we are all in it together.\",94,479  \n  > 2021-03-05 00:09:05,lxz8mq,We just like the stonk ðŸš€ðŸ’ŽðŸ¤²,,5,17  \n  > ... \n\n  Currently, the dataset is split by day, i.e., each file contains only a single day's worth of posts.\n  This was done for data management purposes only, so it is possible to split the input data differently or to even provide just a single file.\n  The only restriction is that file names need to start with `wsb_posts__` and end with `.csv`, othwerwise it won't be recognized as an input file.\n  Furthermore, all files need to start with a header row and follow the column structure described above.\n\n* `wordlist.csv` \n\n  This CSV file contains a list of all english words for the Stock Ticker cleaning.\n  The data is stored only within a single column:\n\n  * `words` (type: String)\n\n  Example:\n\n  > words  \n  > A  \n  > a  \n  > aa  \n  > aal  \n  > aalii  \n  > ...  \n\n  \n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00002-7e8ba601-66bc-4e50-990a-51229d07478e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Usage\n\n\nThe notebook provides an in-depth analyis of posts from the r/wallstreetbets forum in order to derive potenial trading implications.\n\n- The first part focuses on analayzing the various posts in terms of average comments per post (day and stock) as well as the respective sentiment. This is mainly achvieved by composing a new varibale called feature score.\n\n- The second part relates the derived feature score to actual stock movements and allows to compare them in terms of absolute percentage changes. \n\nBy doing so,  predictions for future stock movements can be examined and thus used to beat the market and achieve significant returns.",
   "metadata": {
    "tags": [],
    "cell_id": "00003-1dfb4198-15e4-40ff-a2ad-f1d49b4606bd",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Maintenaince\n\n### Updating the input data:\n\nIn order to generate new input data that contains the latest reddit posts, follow the steps below:\n\n1. Open up `reddit_data_fetch.ipynb`\n2. Configure the subreddit and update the start and end date, as described in the notebook\n3. Execute the notebook and wait until the latest data has been downloaded\n\n### Fine-tuning the Sentiment Analysis:\n\nIn order to improve the sentiment analysis capabilities over time, the custom vocabulary can be extended and/or adjusted.\nTo do this, follow the steps below:\n\n1. Open up `reddit_stock_analysis.ipynb`\n2. Go to section **3.1. Custumize Vocabulary**\n3. Update the existing word-sentiment pairs or add new ones. Sentiment values are denoted as floating point numbers between -1 (very negative sentiment) and 1 (very postive sentiment)\n\n### Changing the Aggregation Time Period\n\nCurrently, day-to-day changes of interest in and prices of stocks are analyzed.\nIt is possible to adjust this time period (e.g. to hour-by-hour aggregation) by following the steps below:\n\n1. Open up `reddit_stock_analysis.ipynb`\n2. Go to section **4. Aggregate Features per Stock per Day**\n3. Instead of converting the posts' timestamps to `%Y-%m-%d` (i.e., removing the hour, minutes and seconds information), choose a different timestamp format\n2. Go to section **5. Fetch Stock Prices**\n3. Instead using the daily close prices delivered by the Yahoo Finance API for further processing, choose the price data suitable for the timestamp format used in step 3\n\n### Refining the Feature Score:\n\nCurrently, the Feature Score is calculated as follows:\n\n> $FeatureScore(day, stock) = log(0.1 + MeanCommentsPerPost(day, stock) * (1 + MeanSentiment(day, stock)))$\n\nThis formula can however be adapted and updated to fit ones specific needs.\n",
   "metadata": {
    "tags": [],
    "cell_id": "00004-f46e44d1-6af9-42de-84d9-99530f1c65cf",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d7886875-5320-40a2-af00-cc1d95e2b7d3' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "6d417842-009f-4c75-acc9-4223911987d9",
  "deepnote_execution_queue": []
 }
}